{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy # used for integer targets\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from random import shuffle, seed\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = reload(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding all titles, training, and target sets composed by Chopin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "1it [00:07,  7.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "2it [00:09,  5.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "3it [00:12,  4.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "4it [00:15,  4.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "5it [00:18,  3.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "6it [00:24,  4.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "7it [00:27,  4.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "8it [00:46,  8.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "9it [00:48,  6.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "10it [00:49,  5.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "11it [00:54,  4.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "12it [01:03,  6.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "13it [01:12,  6.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "14it [01:14,  5.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "15it [01:18,  4.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "16it [01:34,  8.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "17it [01:37,  6.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "18it [01:40,  5.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "19it [01:45,  5.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "20it [01:47,  4.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "21it [01:59,  6.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "22it [02:07,  7.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "23it [02:09,  5.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "24it [02:10,  4.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "25it [02:11,  3.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "26it [02:12,  2.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "27it [02:14,  2.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "28it [02:18,  2.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "29it [02:21,  2.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "30it [02:24,  2.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "31it [02:36,  5.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "32it [02:39,  4.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "33it [02:42,  4.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "34it [02:45,  3.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "35it [02:49,  4.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "36it [02:51,  3.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "37it [02:55,  3.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "38it [02:59,  3.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "39it [03:02,  3.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "40it [03:04,  2.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "41it [03:06,  2.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "42it [03:07,  2.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "43it [03:22,  6.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "44it [03:24,  4.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "45it [03:27,  4.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "46it [03:29,  3.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "47it [03:31,  3.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "48it [03:34,  2.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "49it [03:37,  3.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "50it [03:40,  3.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "51it [03:47,  4.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "52it [03:49,  3.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "53it [03:50,  2.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "54it [03:50,  2.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "55it [03:54,  2.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "56it [03:56,  2.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "57it [03:57,  1.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "58it [03:57,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "59it [03:57,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "60it [03:57,  1.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "61it [03:57,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "62it [03:57,  2.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "63it [03:58,  2.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "64it [03:59,  2.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "66it [03:59,  2.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "67it [03:59,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "68it [04:00,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "69it [04:00,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "70it [04:00,  3.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "71it [04:00,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "72it [04:01,  3.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "73it [04:05,  1.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "74it [04:05,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "75it [04:05,  1.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "76it [04:05,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "77it [04:05,  2.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "78it [04:06,  2.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "79it [04:06,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "80it [04:06,  2.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "82it [04:07,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "83it [04:07,  3.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "84it [04:07,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "85it [04:08,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "86it [04:08,  4.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "87it [04:08,  4.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "88it [04:08,  4.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "89it [04:08,  3.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "90it [04:09,  2.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "91it [04:09,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "92it [04:10,  3.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "93it [04:10,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "94it [04:10,  2.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "95it [04:11,  2.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "96it [04:11,  2.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "97it [04:12,  2.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "98it [04:12,  2.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "99it [04:12,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "100it [04:13,  1.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "101it [04:14,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "102it [04:17,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "103it [04:17,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "104it [04:17,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "105it [04:17,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "106it [04:18,  2.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "107it [04:47,  9.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "108it [04:48,  6.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "109it [04:49,  4.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "110it [04:50,  3.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "111it [04:53,  3.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "112it [04:56,  3.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "113it [04:59,  3.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "114it [05:00,  2.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "115it [05:02,  2.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "116it [05:04,  2.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "117it [05:07,  2.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "118it [05:09,  2.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "119it [05:11,  2.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "120it [05:14,  2.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "121it [05:15,  2.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "122it [05:16,  1.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "123it [05:17,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "124it [05:21,  2.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "125it [05:25,  2.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "126it [05:33,  4.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "127it [05:36,  3.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "128it [05:39,  3.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "129it [05:40,  2.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "130it [05:41,  2.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "131it [05:49,  3.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "132it [05:50,  3.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "133it [05:51,  2.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "134it [05:52,  1.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "135it [05:53,  1.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "136it [05:54,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "137it [05:55,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "138it [05:57,  1.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "139it [06:32, 11.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "140it [06:33,  8.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "141it [06:36,  6.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "142it [06:37,  5.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "143it [06:38,  3.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "144it [06:39,  3.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "145it [06:40,  2.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "146it [06:41,  1.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "147it [06:42,  1.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "148it [06:43,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "149it [06:44,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "150it [06:44,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "151it [06:46,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "152it [06:49,  1.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "153it [06:52,  2.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "154it [06:53,  1.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "155it [06:54,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "156it [06:54,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "157it [06:57,  1.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "158it [06:58,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "159it [07:00,  1.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "160it [07:03,  1.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "161it [07:07,  2.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "162it [07:09,  2.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "163it [07:12,  2.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "164it [07:16,  3.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "165it [07:18,  2.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "166it [07:21,  2.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "167it [07:22,  2.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "168it [07:22,  1.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "169it [07:23,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "170it [07:26,  1.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "171it [07:29,  2.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "172it [07:32,  2.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "173it [07:33,  1.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "174it [07:36,  2.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "175it [07:38,  2.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "176it [07:39,  1.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "177it [07:43,  2.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "178it [07:45,  2.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "179it [07:46,  1.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "180it [07:49,  2.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "181it [07:50,  1.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "182it [07:53,  2.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "183it [07:54,  1.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "184it [07:55,  1.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "185it [07:58,  1.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "186it [07:58,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "187it [08:00,  1.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "188it [08:01,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "189it [08:01,  1.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "190it [08:49, 14.95s/it]\u001b[A\u001b[A\n",
      "\n",
      "192it [08:49, 10.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "194it [08:49,  7.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "195it [08:50,  5.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "196it [08:50,  3.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "197it [08:51,  2.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "198it [08:51,  2.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "199it [08:53,  1.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "200it [08:54,  1.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "201it [08:55,  2.67s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "train = []\n",
    "target = []\n",
    "with open('data/Chopin_input.json', 'r') as handle:\n",
    "    for i,line in enumerate(tqdm(handle)):\n",
    "        song = json.loads(line)\n",
    "        titles.append(song['title'])\n",
    "        train.append(song['train'])\n",
    "        target.append(song['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the unique Chopin songs and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chopin = []\n",
    "keep_indices = []\n",
    "for i,song in enumerate(titles):\n",
    "    if 'andante' in song:\n",
    "        song = 'andante op 22'\n",
    "    if 'ballade no. 2' in song:\n",
    "        song = 'ballade no 2'\n",
    "    if 'barcarolle' in song:\n",
    "        song = 'barcarolle'\n",
    "    if 'berceuse' in song:\n",
    "        song = 'barceuse'\n",
    "    if 'etude op. 10 no. 1' in song:\n",
    "        song = 'etude op. 10 no. 1'\n",
    "    if 'etude op. 10 no. 12' in song:\n",
    "        song = 'etude op. 10 no. 12'\n",
    "    if 'etude op. 10 no. 2' in song:\n",
    "        song = 'etude op. 10 no. 2'\n",
    "    if 'etude op. 10 no. 4' in song:\n",
    "        song = 'etude op. 10 no. 4'\n",
    "    if 'etude op. 10 no. 8' in song:\n",
    "        song = 'etude op. 10 no. 8'\n",
    "    if 'etude op. 25 no. 1' in song:\n",
    "        song = 'etude op. 25 no. 1'\n",
    "    if 'etude op. 25 no. 10' in song:\n",
    "        song = 'etude op. 25 no. 10'\n",
    "    if 'etude op. 25 no. 11' in song:\n",
    "        song = 'etude op. 25 no. 11'\n",
    "    if 'etude op. 25 no. 12' in song:\n",
    "        song = 'etude op. 25 no. 12'\n",
    "    if 'etude op. 25 no. 6' in song:\n",
    "        song = 'etude op. 25 no. 6'\n",
    "    if 'op. 49' in song:\n",
    "        song = 'fantasy op. 49'\n",
    "    if 'polonaise-fantasie' in song:\n",
    "        song = 'polonaise-fantasie'\n",
    "    if 'scherzo no. 2' in song:\n",
    "        song = 'scherzo no. 2'\n",
    "    if 'scherzo no. 3' in song:\n",
    "        song = 'scherzo no. 3'\n",
    "    if 'scherzo no. 4' in song:\n",
    "        song = 'scherzo no. 4'\n",
    "    if 'sonata no. 3' in song:\n",
    "        song = 'sonata no. 3'\n",
    "    if song not in unique_chopin:\n",
    "        unique_chopin.append(song)\n",
    "        keep_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train = []\n",
    "for i,each in enumerate(train):\n",
    "    if i in keep_indices:\n",
    "        unique_train.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_target = []\n",
    "for i, each in enumerate(target):\n",
    "    if i in keep_indices:\n",
    "        unique_target.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_chopin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/chopin_titles.json', 'w') as to_write:\n",
    "    for each in unique_chopin:\n",
    "        json.dump(each, to_write)\n",
    "        to_write.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(seq_len, unique_notes, dropout=0.3, output_emb=100, rnn_unit=128, dense_unit=64):\n",
    "    inputs = tf.keras.layers.Input(shape=(seq_len,))\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=unique_notes+1, output_dim=output_emb, input_length=seq_len)(inputs)\n",
    "    forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit, return_sequences=True))(embedding)\n",
    "    forward_pass , att_vector = SeqSelfAttention(\n",
    "        return_attention=True,\n",
    "        attention_activation='sigmoid',\n",
    "        attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "        attention_width=50,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "        bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "        attention_regularizer_weight=1e-4,\n",
    "        )(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit, return_sequences=True))(forward_pass)\n",
    "    forward_pass , att_vector2 = SeqSelfAttention(\n",
    "        return_attention=True,\n",
    "        attention_activation='sigmoid',\n",
    "        attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "        attention_width=50,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "        bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "        attention_regularizer_weight=1e-4,\n",
    "        )(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit))(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dense(dense_unit)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.LeakyReLU()(forward_pass)\n",
    "    outputs = tf.keras.layers.Dense(unique_notes+1, activation = \"softmax\")(forward_pass)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='generate_scores_rnn')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = [y for x in unique_target for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_notes = max(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(50, unique_notes+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generate_scores_rnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 100)           10995600  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 256)           176640    \n",
      "_________________________________________________________________\n",
      "seq_self_attention (SeqSelfA [(None, 50, 256), (None,  65537     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 50, 256)           296448    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_1 (SeqSel [(None, 50, 256), (None,  65537     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 256)               296448    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 109956)            7147140   \n",
      "=================================================================\n",
      "Total params: 19,059,798\n",
      "Trainable params: 19,059,798\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam()\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 model=model)\n",
    "checkpoint_dir = 'models/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "loss_fn = sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rnn_models\n",
    "# from rnn_models import SeqSelfAttention\n",
    "# from rnn_models import TrainModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy # used for integer targets\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle, seed, sample\n",
    "\n",
    "\n",
    "## Class for self sequecing layer from github\n",
    "class SeqSelfAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    ATTENTION_TYPE_ADD = 'additive'\n",
    "    ATTENTION_TYPE_MUL = 'multiplicative'\n",
    "\n",
    "    def __init__(self,\n",
    "                 units=32,\n",
    "                 attention_width=None,\n",
    "                 attention_type=ATTENTION_TYPE_ADD,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 use_additive_bias=True,\n",
    "                 use_attention_bias=True,\n",
    "                 attention_activation=None,\n",
    "                 attention_regularizer_weight=0.0,\n",
    "                 **kwargs):\n",
    "        \"\"\"Layer initialization.\n",
    "        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n",
    "        :param units: The dimension of the vectors that used to calculate the attention weights.\n",
    "        :param attention_width: The width of local attention.\n",
    "        :param attention_type: 'additive' or 'multiplicative'.\n",
    "        :param return_attention: Whether to return the attention weights for visualization.\n",
    "        :param history_only: Only use historical pieces of data.\n",
    "        :param kernel_initializer: The initializer for weight matrices.\n",
    "        :param bias_initializer: The initializer for biases.\n",
    "        :param kernel_regularizer: The regularization for weight matrices.\n",
    "        :param bias_regularizer: The regularization for biases.\n",
    "        :param kernel_constraint: The constraint for weight matrices.\n",
    "        :param bias_constraint: The constraint for biases.\n",
    "        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n",
    "                                  in additive mode.\n",
    "        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n",
    "        :param attention_activation: The activation used for calculating the weights of attention.\n",
    "        :param attention_regularizer_weight: The weights of attention regularizer.\n",
    "        :param kwargs: Parameters for parent class.\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.units = units\n",
    "        self.attention_width = attention_width\n",
    "        self.attention_type = attention_type\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        if history_only and attention_width is None:\n",
    "            self.attention_width = int(1e9)\n",
    "\n",
    "        self.use_additive_bias = use_additive_bias\n",
    "        self.use_attention_bias = use_attention_bias\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
    "        self.attention_activation = tf.keras.activations.get(attention_activation)\n",
    "        self.attention_regularizer_weight = attention_regularizer_weight\n",
    "        self._backend = tf.keras.backend.backend()\n",
    "\n",
    "        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self.Wx, self.Wt, self.bh = None, None, None\n",
    "            self.Wa, self.ba = None, None\n",
    "        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self.Wa, self.ba = None, None\n",
    "        else:\n",
    "            raise NotImplementedError('No implementation for attention type : ' + attention_type)\n",
    "\n",
    "        super(SeqSelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'attention_width': self.attention_width,\n",
    "            'attention_type': self.attention_type,\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "            'use_additive_bias': self.use_additive_bias,\n",
    "            'use_attention_bias': self.use_attention_bias,\n",
    "            'kernel_initializer': tf.keras.regularizers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': tf.keras.regularizers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': tf.keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': tf.keras.regularizers.serialize(self.bias_regularizer),\n",
    "            'kernel_constraint': tf.keras.constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': tf.keras.constraints.serialize(self.bias_constraint),\n",
    "            'attention_activation': tf.keras.activations.serialize(self.attention_activation),\n",
    "            'attention_regularizer_weight': self.attention_regularizer_weight,\n",
    "        }\n",
    "        base_config = super(SeqSelfAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self._build_additive_attention(input_shape)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self._build_multiplicative_attention(input_shape)\n",
    "        super(SeqSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def _build_additive_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wt'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wx'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_additive_bias:\n",
    "            self.bh = self.add_weight(shape=(self.units,),\n",
    "                                      name='{}_Add_bh'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(self.units, 1),\n",
    "                                  name='{}_Add_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Add_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def _build_multiplicative_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n",
    "                                  name='{}_Mul_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Mul_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            inputs, positions = inputs\n",
    "            positions = K.cast(positions, 'int32')\n",
    "            mask = mask[1]\n",
    "        else:\n",
    "            positions = None\n",
    "\n",
    "        input_len = K.shape(inputs)[1]\n",
    "\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            e = self._call_additive_emission(inputs)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            e = self._call_multiplicative_emission(inputs)\n",
    "\n",
    "        if self.attention_activation is not None:\n",
    "            e = self.attention_activation(e)\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        if self.attention_width is not None:\n",
    "            ones = tf.ones((input_len, input_len))\n",
    "            if self.history_only:\n",
    "                local = tf.linalg.band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width - 1),\n",
    "                    0,\n",
    "                )\n",
    "            else:\n",
    "                local = tf.linalg.band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width // 2),\n",
    "                    K.minimum(input_len, (self.attention_width - 1) // 2),\n",
    "                )\n",
    "            e = e * K.expand_dims(local, 0)\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            e = K.permute_dimensions(K.permute_dimensions(e * mask, (0, 2, 1)) * mask, (0, 2, 1))\n",
    "\n",
    "        # a_{t} = \\text{softmax}(e_t)\n",
    "        s = K.sum(e, axis=-1)\n",
    "        s = K.tile(K.expand_dims(s, axis=-1), K.stack([1, 1, input_len]))\n",
    "        a = e / (s + K.epsilon())\n",
    "\n",
    "        # l_t = \\sum_{t'} a_{t, t'} x_{t'}\n",
    "        v = K.batch_dot(a, inputs)\n",
    "        if self.attention_regularizer_weight > 0.0:\n",
    "            self.add_loss(self._attention_regularizer(a))\n",
    "\n",
    "        if positions is not None:\n",
    "            pos_num = K.shape(positions)[1]\n",
    "            batch_indices = K.tile(K.expand_dims(K.arange(K.shape(inputs)[0]), axis=-1), K.stack([1, pos_num]))\n",
    "            pos_indices = K.stack([batch_indices, positions], axis=-1)\n",
    "            v = tf.gather_nd(v, pos_indices)\n",
    "            a = tf.gather_nd(a, pos_indices)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v\n",
    "\n",
    "    def _call_additive_emission(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size, input_len = input_shape[0], input_shape[1]\n",
    "\n",
    "        # h_{t, t'} = \\tanh(x_t^T W_t + x_{t'}^T W_x + b_h)\n",
    "        q, k = K.dot(inputs, self.Wt), K.dot(inputs, self.Wx)\n",
    "        q = K.tile(K.expand_dims(q, 2), K.stack([1, 1, input_len, 1]))\n",
    "        k = K.tile(K.expand_dims(k, 1), K.stack([1, input_len, 1, 1]))\n",
    "        if self.use_additive_bias:\n",
    "            h = K.tanh(q + k + self.bh)\n",
    "        else:\n",
    "            h = K.tanh(q + k)\n",
    "\n",
    "        # e_{t, t'} = W_a h_{t, t'} + b_a\n",
    "        if self.use_attention_bias:\n",
    "            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n",
    "        else:\n",
    "            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n",
    "        return e\n",
    "\n",
    "    def _call_multiplicative_emission(self, inputs):\n",
    "        # e_{t, t'} = x_t^T W_a x_{t'} + b_a\n",
    "        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n",
    "        if self.use_attention_bias:\n",
    "            e = e + self.ba\n",
    "        return e\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape, pos_shape = input_shape\n",
    "            output_shape = (input_shape[0], pos_shape[1], input_shape[2])\n",
    "        else:\n",
    "            output_shape = input_shape\n",
    "        if self.return_attention:\n",
    "            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n",
    "            return [output_shape, attention_shape]\n",
    "        return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list):\n",
    "            mask = mask[1]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def _attention_regularizer(self, attention):\n",
    "        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n",
    "        input_len = K.shape(attention)[-1]\n",
    "        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n",
    "            attention,\n",
    "            K.permute_dimensions(attention, (0, 2, 1))) - tf.eye(input_len))) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "        return {'SeqSelfAttention': SeqSelfAttention}\n",
    "\n",
    "# Training Model Class\n",
    "class TrainModel:\n",
    "\n",
    "    def __init__(self, epochs, sample_train, sample_target, batch_nnet_size, batch_song, optimizer, checkpoint, loss_fn,checkpoint_prefix, total_songs, model):\n",
    "        self.epochs = epochs\n",
    "        self.sample_train = sample_train\n",
    "        self.sample_target = sample_target\n",
    "        self.batch_nnet_size = batch_nnet_size\n",
    "        self.batch_song = batch_song\n",
    "        self.optimizer = optimizer\n",
    "        self.checkpoint = checkpoint\n",
    "        self.loss_fn = loss_fn\n",
    "        self.checkpoint_prefix = checkpoint_prefix\n",
    "        self.total_songs = total_songs\n",
    "        self.model = model\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in tqdm_notebook(range(self.epochs),desc='epochs'):\n",
    "            # for each epoch, shuffle the list of all the songs\n",
    "            c = list(zip(self.sample_train, self.sample_target))\n",
    "            shuffle(c)\n",
    "            self.sample_train, self.sample_target = zip(*c)\n",
    "            loss_total = 0\n",
    "            steps = 0\n",
    "            steps_nnet = 0\n",
    "            # Iterate all songs by the length of sample input (total_songs) and batches (batch_song)\n",
    "            for i in tqdm_notebook(range(0,self.total_songs, self.batch_song), desc='MUSIC'):\n",
    "                # EXAMPLE: [0,5,10,15,20] FOR TOTAL_SONGS = 20 AND BATCH_SONG = 5\n",
    "                steps += 1\n",
    "                #inputs_nnet_large, outputs_nnet_large = generate_batch_song(\n",
    "                 #   self.sample_input, self.batch_song, start_index=i, fs=self.frame_per_second,\n",
    "                  #  seq_len=seq_len, use_tqdm=False) # We use the function that have been defined here\n",
    "                #inputs_nnet_large = np.array(self.note_tokenizer.transform(inputs_nnet_large), dtype=np.int32)\n",
    "                #outputs_nnet_large = np.array(self.note_tokenizer.transform(outputs_nnet_large), dtype=np.int32)\n",
    "\n",
    "                # EXAMPLE LARGE INPUTS = ARRAY([1,2,3,4],[2,3,4,5],[2,3,4,5],[2,3,4,5],[1,2,3,4])\n",
    "                input_batch = [y for x in self.sample_train[i:i+self.batch_song] for y in x]\n",
    "                output_batch = [y for x in self.sample_target[i:i+self.batch_song] for y in x]\n",
    "                c = list(zip(input_batch, output_batch))\n",
    "                sample_in = sample(c, 10000)\n",
    "                input_batch, output_batch = zip(*sample_in)\n",
    "                inputs_nnet_large = np.array(input_batch)\n",
    "                outputs_nnet_large = np.array(output_batch)\n",
    "\n",
    "                # Get an index of all windows in a song\n",
    "                index_shuffled = np.arange(start=0, stop=len(inputs_nnet_large))\n",
    "                np.random.shuffle(index_shuffled)\n",
    "\n",
    "                for nnet_steps in tqdm_notebook(range(0,len(index_shuffled),self.batch_nnet_size)):\n",
    "                    steps_nnet += 1\n",
    "                    current_index = index_shuffled[nnet_steps:nnet_steps+self.batch_nnet_size]\n",
    "\n",
    "                    inputs_nnet, outputs_nnet = inputs_nnet_large[current_index], outputs_nnet_large[current_index]\n",
    "\n",
    "                    # To make sure no exception thrown by tensorflow on autograph\n",
    "                    if len(inputs_nnet) // self.batch_nnet_size != 1:\n",
    "                        break\n",
    "                    loss = self.train_step(inputs_nnet, outputs_nnet)\n",
    "                    loss_total += tf.math.reduce_sum(loss)\n",
    "                    if steps_nnet % 20 == 0:\n",
    "                        print(\"epochs {} | Steps {} | total loss : {}\".format(epoch + 1, steps_nnet,loss_total))\n",
    "\n",
    "                    #checkpoint.save(file_prefix = self.checkpoint_prefix)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = self.model(inputs)\n",
    "            loss = self.loss_fn(targets, prediction)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "EPOCHS = 2\n",
    "BATCH_SONG = 10\n",
    "BATCH_NNET_SIZE = 96\n",
    "TOTAL_SONGS = len(unique_target)\n",
    "FRAME_PER_SECOND = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafa5fc0d82f4c3fb82036e3cdc78168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epochs', max=2, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aabca96d4e42ac96eb8e456053f735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MUSIC', max=11, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f41db571f2b45a4a32e3bd3e3963a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 20 | total loss : 15204.35546875\n",
      "epochs 1 | Steps 40 | total loss : 30480.626953125\n",
      "epochs 1 | Steps 60 | total loss : 45556.1171875\n",
      "epochs 1 | Steps 80 | total loss : 60398.91796875\n",
      "epochs 1 | Steps 100 | total loss : 75496.8046875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a1194344f649e18b47ee5bda44c5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 120 | total loss : 89402.5859375\n",
      "epochs 1 | Steps 140 | total loss : 103897.75\n",
      "epochs 1 | Steps 160 | total loss : 118101.7421875\n",
      "epochs 1 | Steps 180 | total loss : 132250.125\n",
      "epochs 1 | Steps 200 | total loss : 146228.03125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0039d94043b24d4c8dee55ea8f318682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 220 | total loss : 159385.015625\n",
      "epochs 1 | Steps 240 | total loss : 173710.984375\n",
      "epochs 1 | Steps 260 | total loss : 188204.078125\n",
      "epochs 1 | Steps 280 | total loss : 202152.609375\n",
      "epochs 1 | Steps 300 | total loss : 216107.09375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ded8b4ea6474509ba47e61213b5a48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 320 | total loss : 229489.34375\n",
      "epochs 1 | Steps 340 | total loss : 243486.703125\n",
      "epochs 1 | Steps 360 | total loss : 257412.921875\n",
      "epochs 1 | Steps 380 | total loss : 270663.21875\n",
      "epochs 1 | Steps 400 | total loss : 283806.90625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2362f61d17fa4b1192f99550ec42357e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 440 | total loss : 310686.28125\n",
      "epochs 1 | Steps 460 | total loss : 324775.375\n",
      "epochs 1 | Steps 480 | total loss : 338483.9375\n",
      "epochs 1 | Steps 500 | total loss : 352154.1875\n",
      "epochs 1 | Steps 520 | total loss : 365644.34375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7d4955e7c54aa898defea9a6a5eaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 540 | total loss : 378592.09375\n",
      "epochs 1 | Steps 560 | total loss : 392196.28125\n",
      "epochs 1 | Steps 580 | total loss : 405647.8125\n",
      "epochs 1 | Steps 600 | total loss : 418868.34375\n",
      "epochs 1 | Steps 620 | total loss : 432206.03125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536ba6d43f7b4ee8a07eecf7320e38bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 640 | total loss : 444555.59375\n",
      "epochs 1 | Steps 660 | total loss : 457113.3125\n",
      "epochs 1 | Steps 680 | total loss : 470058.1875\n",
      "epochs 1 | Steps 700 | total loss : 482893.3125\n",
      "epochs 1 | Steps 720 | total loss : 495289.90625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75c66a90cae4da7b6451588626e4137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 740 | total loss : 507698.65625\n",
      "epochs 1 | Steps 760 | total loss : 521585.90625\n",
      "epochs 1 | Steps 780 | total loss : 535380.8125\n",
      "epochs 1 | Steps 800 | total loss : 548778.4375\n",
      "epochs 1 | Steps 820 | total loss : 562063.6875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6b1bf1215b493bbe88d5754e117549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 860 | total loss : 587395.125\n",
      "epochs 1 | Steps 880 | total loss : 600208.6875\n",
      "epochs 1 | Steps 900 | total loss : 612754.875\n",
      "epochs 1 | Steps 920 | total loss : 625003.75\n",
      "epochs 1 | Steps 940 | total loss : 637115.25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4540d0f216be470baf5e2f2d5b9d6e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 960 | total loss : 649291.25\n",
      "epochs 1 | Steps 980 | total loss : 662233.3125\n",
      "epochs 1 | Steps 1000 | total loss : 674889.4375\n",
      "epochs 1 | Steps 1020 | total loss : 687677.4375\n",
      "epochs 1 | Steps 1040 | total loss : 700246.125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e85bb0f84a4120aa53752b69cf97ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 1060 | total loss : 712483.75\n",
      "epochs 1 | Steps 1080 | total loss : 725219.4375\n",
      "epochs 1 | Steps 1100 | total loss : 737270.25\n",
      "epochs 1 | Steps 1120 | total loss : 749444.9375\n",
      "epochs 1 | Steps 1140 | total loss : 761328.9375\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0cb50ebcf145429948674984019708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MUSIC', max=11, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acb9c1b7a524415a3cd3a0ca1f1e0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 20 | total loss : 12235.81640625\n",
      "epochs 2 | Steps 40 | total loss : 23750.42578125\n",
      "epochs 2 | Steps 60 | total loss : 35191.3125\n",
      "epochs 2 | Steps 80 | total loss : 46602.9765625\n",
      "epochs 2 | Steps 100 | total loss : 57893.53125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c476cb66693e446c9db927c51d28d46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 120 | total loss : 69390.2265625\n",
      "epochs 2 | Steps 140 | total loss : 81625.71875\n",
      "epochs 2 | Steps 160 | total loss : 93368.1640625\n",
      "epochs 2 | Steps 180 | total loss : 105258.875\n",
      "epochs 2 | Steps 200 | total loss : 116706.0390625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfefa72443214beb962aadec1e4d4c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 220 | total loss : 128076.7890625\n",
      "epochs 2 | Steps 240 | total loss : 139751.328125\n",
      "epochs 2 | Steps 260 | total loss : 151137.828125\n",
      "epochs 2 | Steps 280 | total loss : 162304.609375\n",
      "epochs 2 | Steps 300 | total loss : 174077.828125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9de6e8b52c84370a24505d8f441f7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 320 | total loss : 185188.265625\n",
      "epochs 2 | Steps 340 | total loss : 198497.890625\n",
      "epochs 2 | Steps 360 | total loss : 211492.6875\n",
      "epochs 2 | Steps 380 | total loss : 224559.03125\n",
      "epochs 2 | Steps 400 | total loss : 237494.453125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8700c0f3859c4e2183b686a52e1fe11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 440 | total loss : 262646.375\n",
      "epochs 2 | Steps 460 | total loss : 274862.90625\n",
      "epochs 2 | Steps 480 | total loss : 287181.6875\n",
      "epochs 2 | Steps 500 | total loss : 299001.40625\n",
      "epochs 2 | Steps 520 | total loss : 310966.4375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f6f6b50587453d800068a50460f2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 540 | total loss : 322746.375\n",
      "epochs 2 | Steps 560 | total loss : 334680.03125\n",
      "epochs 2 | Steps 580 | total loss : 346790.34375\n",
      "epochs 2 | Steps 600 | total loss : 358301.03125\n",
      "epochs 2 | Steps 620 | total loss : 369929.125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd5162bbe92404981fe180216c602e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 640 | total loss : 381170.9375\n",
      "epochs 2 | Steps 660 | total loss : 393098.71875\n",
      "epochs 2 | Steps 680 | total loss : 405084.40625\n",
      "epochs 2 | Steps 700 | total loss : 416521.6875\n",
      "epochs 2 | Steps 720 | total loss : 428324.625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3130bf1d06147c1b815c341aff9fc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 740 | total loss : 439123.75\n",
      "epochs 2 | Steps 760 | total loss : 450980.125\n",
      "epochs 2 | Steps 780 | total loss : 462519.71875\n",
      "epochs 2 | Steps 800 | total loss : 473749.03125\n",
      "epochs 2 | Steps 820 | total loss : 485104.46875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d2867316cb4859b5433f8aa45f3637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 860 | total loss : 507611.75\n",
      "epochs 2 | Steps 880 | total loss : 519662.8125\n",
      "epochs 2 | Steps 900 | total loss : 531471.9375\n",
      "epochs 2 | Steps 920 | total loss : 543131.625\n",
      "epochs 2 | Steps 940 | total loss : 554746.3125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848a07bb2dbc4572b4ebcc4e51ad12f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 960 | total loss : 565464.125\n",
      "epochs 2 | Steps 980 | total loss : 576777.5\n",
      "epochs 2 | Steps 1000 | total loss : 587747.125\n",
      "epochs 2 | Steps 1020 | total loss : 598834.9375\n",
      "epochs 2 | Steps 1040 | total loss : 609534.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cdd5a34f4440f4894648070f812b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 1060 | total loss : 620000.25\n",
      "epochs 2 | Steps 1080 | total loss : 631571.3125\n",
      "epochs 2 | Steps 1100 | total loss : 642735.5625\n",
      "epochs 2 | Steps 1120 | total loss : 653739.9375\n",
      "epochs 2 | Steps 1140 | total loss : 664876.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_class = TrainModel(EPOCHS, unique_train, unique_target, BATCH_NNET_SIZE, BATCH_SONG, optimizer, checkpoint, loss_fn, checkpoint_prefix, \n",
    "                        TOTAL_SONGS, model)\n",
    "train_class.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.train' has no attribute 'Saver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6796249016c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chopin_s107_ep2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.train' has no attribute 'Saver'"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(model, 'chopin_s107_ep2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('chopin_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-8a4e241a21bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chopin_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \"\"\"\n\u001b[1;32m    974\u001b[0m     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m--> 975\u001b[0;31m                       signatures, options)\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    110\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    111\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 112\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mmodel_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    160\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1940\u001b[0m           \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1942\u001b[0;31m     \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1943\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     return serialize_keras_class_and_config(instance.__class__.__name__,\n\u001b[0;32m--> 140\u001b[0;31m                                             instance.get_config())\n\u001b[0m\u001b[1;32m    141\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-17b9f34f05d5>\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;34m'attention_regularizer_weight'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_regularizer_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         }\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mbase_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeqSelfAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model.save('chopin_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-7d56af4e7aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# serialize model to JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chopin_model.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# serialize weights to HDF5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mto_json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mJSON\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \"\"\"\n\u001b[0;32m-> 1209\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m     return json.dumps(\n\u001b[1;32m   1211\u001b[0m         model_config, default=serialization.get_json_type, **kwargs)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_updated_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m     model_config = {\n\u001b[1;32m   1189\u001b[0m         \u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1940\u001b[0m           \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1942\u001b[0;31m     \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1943\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     return serialize_keras_class_and_config(instance.__class__.__name__,\n\u001b[0;32m--> 140\u001b[0;31m                                             instance.get_config())\n\u001b[0m\u001b[1;32m    141\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-17b9f34f05d5>\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;34m'attention_regularizer_weight'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_regularizer_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         }\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mbase_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeqSelfAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"chopin_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"chopin_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
