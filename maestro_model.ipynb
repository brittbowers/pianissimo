{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gast==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy # used for integer targets\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from random import shuffle, seed, sample\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding all titles, training, and target sets composed by Chopin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Input file into title, train, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:14,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "titles_h = []\n",
    "train_h = []\n",
    "target_h = []\n",
    "with open('data/Haydn_input.json', 'r') as handle: # EDIT WITH COMPOSER\n",
    "    for i,line in enumerate(tqdm(handle)):\n",
    "        song = json.loads(line)\n",
    "        titles_h.append(song['title'])\n",
    "        train_h.append(song['train'])\n",
    "        target_h.append(song['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "407it [05:43,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "train = []\n",
    "target = []\n",
    "with open('data/Sonata_input.json', 'r') as handle: # EDIT WITH COMPOSER\n",
    "    for i,line in enumerate(tqdm(handle)):\n",
    "        song = json.loads(line)\n",
    "        titles.append(song['title'])\n",
    "        train.append(song['train'])\n",
    "        target.append(song['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below for Parsing Chopin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chopin = []\n",
    "keep_indices = []\n",
    "for i,song in enumerate(titles):\n",
    "    song = song.lower()\n",
    "    if 'andante' in song:\n",
    "        song = 'andante op 22'\n",
    "    if 'ballade no. 2' in song:\n",
    "        song = 'ballade no 2'\n",
    "    if 'barcarolle' in song:\n",
    "        song = 'barcarolle'\n",
    "    if 'berceuse' in song:\n",
    "        song = 'barceuse'\n",
    "    if 'etude op. 10 no. 1' in song:\n",
    "        song = 'etude op. 10 no. 1'\n",
    "    if 'etude op. 10 no. 12' in song:\n",
    "        song = 'etude op. 10 no. 12'\n",
    "    if 'etude op. 10 no. 2' in song:\n",
    "        song = 'etude op. 10 no. 2'\n",
    "    if 'etude op. 10 no. 4' in song:\n",
    "        song = 'etude op. 10 no. 4'\n",
    "    if 'etude op. 10 no. 8' in song:\n",
    "        song = 'etude op. 10 no. 8'\n",
    "    if 'etude op. 25 no. 1' in song:\n",
    "        song = 'etude op. 25 no. 1'\n",
    "    if 'etude op. 25 no. 10' in song:\n",
    "        song = 'etude op. 25 no. 10'\n",
    "    if 'etude op. 25 no. 11' in song:\n",
    "        song = 'etude op. 25 no. 11'\n",
    "    if 'etude op. 25 no. 12' in song:\n",
    "        song = 'etude op. 25 no. 12'\n",
    "    if 'etude op. 25 no. 6' in song:\n",
    "        song = 'etude op. 25 no. 6'\n",
    "    if 'op. 49' in song:\n",
    "        song = 'fantasy op. 49'\n",
    "    if 'polonaise-fantasie' in song:\n",
    "        song = 'polonaise-fantasie'\n",
    "    if 'scherzo no. 2' in song:\n",
    "        song = 'scherzo no. 2'\n",
    "    if 'scherzo no. 3' in song:\n",
    "        song = 'scherzo no. 3'\n",
    "    if 'scherzo no. 4' in song:\n",
    "        song = 'scherzo no. 4'\n",
    "    if 'sonata no. 3' in song:\n",
    "        song = 'sonata no. 3'\n",
    "    if song not in unique_chopin:\n",
    "        unique_chopin.append(song)\n",
    "        keep_indices.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below for Parsing Brahms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_brahms = []\n",
    "keep_indices = []\n",
    "for i,song in enumerate(titles):\n",
    "    song = song.lower()\n",
    "    if 'sonata in' in song:\n",
    "        song = 'sonata in f minor op 5'\n",
    "    if song not in unique_brahms:\n",
    "        unique_brahms.append(song)\n",
    "        keep_indices.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below for Parsing Sonatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_son = []\n",
    "keep_indices = []\n",
    "for i,song in enumerate(titles):\n",
    "    if song not in unique_son:\n",
    "        unique_son.append(song)\n",
    "        keep_indices.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below for Parsing Hadyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ha = []\n",
    "keep_indices = []\n",
    "for i,song in enumerate(titles_h):\n",
    "    if song not in unique_ha:\n",
    "        unique_ha.append(song)\n",
    "        keep_indices.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping Unique Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train = []\n",
    "for i,each in enumerate(train_h):\n",
    "    if i in keep_indices:\n",
    "        unique_train.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_target = []\n",
    "for i, each in enumerate(target_h):\n",
    "    if i in keep_indices:\n",
    "        unique_target.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_ha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(seq_len, unique_notes, dropout=0.3, output_emb=100, rnn_unit=128, dense_unit=64):\n",
    "    inputs = tf.keras.layers.Input(shape=(seq_len,))\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=unique_notes, output_dim=output_emb, input_length=seq_len)(inputs)\n",
    "    forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit, return_sequences=True))(embedding)\n",
    "#     #forward_pass , att_vector = SeqSelfAttention(\n",
    "#         return_attention=True,\n",
    "#         attention_activation='sigmoid',\n",
    "#         attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "#         attention_width=50,\n",
    "#         kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "#         bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "#         attention_regularizer_weight=1e-4,\n",
    "#         )(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit, return_sequences=True))(forward_pass)\n",
    "#     forward_pass , att_vector2 = SeqSelfAttention(\n",
    "#         return_attention=True,\n",
    "#         attention_activation='sigmoid',\n",
    "#         attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL, # multiplicative\n",
    "#         attention_width=50,\n",
    "#         kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "#         bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "#         attention_regularizer_weight=1e-4,\n",
    "#         )(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit))(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dense(dense_unit)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.LeakyReLU()(forward_pass)\n",
    "    outputs = tf.keras.layers.Dense(unique_notes, activation = \"softmax\")(forward_pass)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='generate_scores_rnn')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/Haydn_index.json', 'r') as read_file:\n",
    "    dict_index = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_notes = len(dict_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16870"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(50, unique_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generate_scores_rnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 50, 100)           1687000   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 50, 256)           175872    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 50, 256)           295680    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 256)               295680    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16870)             1096550   \n",
      "=================================================================\n",
      "Total params: 3,567,230\n",
      "Trainable params: 3,567,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam()\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 model=model)\n",
    "checkpoint_dir = 'models/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "loss_fn = sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "  \n",
    "    def __init__(self, epochs, sample_train, sample_target, batch_nnet_size, batch_song, optimizer, checkpoint, loss_fn,\n",
    "               checkpoint_prefix, total_songs, model):\n",
    "        self.epochs = epochs\n",
    "        self.sample_train = sample_train\n",
    "        self.sample_target = sample_target\n",
    "        self.batch_nnet_size = batch_nnet_size\n",
    "        self.batch_song = batch_song\n",
    "        self.optimizer = optimizer\n",
    "        self.checkpoint = checkpoint\n",
    "        self.loss_fn = loss_fn\n",
    "        self.checkpoint_prefix = checkpoint_prefix\n",
    "        self.total_songs = total_songs\n",
    "        self.model = model\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in tqdm_notebook(range(self.epochs),desc='epochs'):\n",
    "            # for each epochs, we shuffle the list of all the datasets\n",
    "            c = list(zip(self.sample_train, self.sample_target))\n",
    "            shuffle(c)\n",
    "            self.sample_train, self.sample_target = zip(*c)\n",
    "            loss_total = 0\n",
    "            steps = 0\n",
    "            steps_nnet = 0\n",
    "\n",
    "            # Iterate all songs by the length of sample input (total_songs) and batches (batch_song)\n",
    "            for i in tqdm_notebook(range(0,self.total_songs, self.batch_song), desc='MUSIC'):\n",
    "                # EXAMPLE: [0,5,10,15,20] FOR TOTAL_SONGS = 20 AND BATCH_SONG = 5\n",
    "                steps += 1\n",
    "                #inputs_nnet_large, outputs_nnet_large = generate_batch_song(\n",
    "                 #   self.sample_input, self.batch_song, start_index=i, fs=self.frame_per_second, \n",
    "                  #  seq_len=seq_len, use_tqdm=False) # We use the function that have been defined here\n",
    "                #inputs_nnet_large = np.array(self.note_tokenizer.transform(inputs_nnet_large), dtype=np.int32)\n",
    "                #outputs_nnet_large = np.array(self.note_tokenizer.transform(outputs_nnet_large), dtype=np.int32)\n",
    "                \n",
    "                # EXAMPLE LARGE INPUTS = ARRAY([1,2,3,4],[2,3,4,5],[2,3,4,5],[2,3,4,5],[1,2,3,4])\n",
    "                input_batch = [y for x in self.sample_train[i:i+self.batch_song] for y in x]\n",
    "                output_batch = [y for x in self.sample_target[i:i+self.batch_song] for y in x]\n",
    "                c = list(zip(input_batch, output_batch))\n",
    "                all_sample = sample(c, 10000)\n",
    "#                 start = c[0:5000]\n",
    "#                 middle = int(len(c)/2)\n",
    "#                 middle_left = c[middle:middle-5000]\n",
    "#                 middle_right = c[middle:middle+5000]\n",
    "#                 end = c[-5000:]\n",
    "#                 all_sample = start + middle_left + middle_right + end\n",
    "                input_batch, output_batch = zip(*all_sample)\n",
    "                inputs_nnet_large = np.array(input_batch)\n",
    "                outputs_nnet_large = np.array(output_batch)\n",
    "\n",
    "                # Get an index of all windows in a song\n",
    "                index_shuffled = np.arange(start=0, stop=len(inputs_nnet_large))\n",
    "                np.random.shuffle(index_shuffled)\n",
    "                \n",
    "                for nnet_steps in tqdm_notebook(range(0,len(index_shuffled),self.batch_nnet_size)):\n",
    "                    steps_nnet += 1\n",
    "                    current_index = index_shuffled[nnet_steps:nnet_steps+self.batch_nnet_size]\n",
    "\n",
    "                    inputs_nnet, outputs_nnet = inputs_nnet_large[current_index], outputs_nnet_large[current_index]\n",
    "\n",
    "                    # To make sure no exception thrown by tensorflow on autograph\n",
    "                    if len(inputs_nnet) // self.batch_nnet_size != 1:\n",
    "                        break\n",
    "                    loss = self.train_step(inputs_nnet, outputs_nnet)\n",
    "                    loss_total += tf.math.reduce_sum(loss)\n",
    "                    if steps_nnet % 20 == 0:\n",
    "                        print(\"epochs {} | Steps {} | total loss : {}\".format(epoch + 1, steps_nnet,loss_total))\n",
    "\n",
    "                    #checkpoint.save(file_prefix = self.checkpoint_prefix)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = self.model(inputs)\n",
    "            loss = self.loss_fn(targets, prediction)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "EPOCHS = 5\n",
    "BATCH_SONG = 5\n",
    "BATCH_NNET_SIZE = 96\n",
    "TOTAL_SONGS = len(unique_target)\n",
    "FRAME_PER_SECOND = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bc046259564e2d82f0abb29202147f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='epochs', max=5.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:28: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef5755c95e340329c0c986b78b43f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='MUSIC', max=6.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:56: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198e6090581d4a998b08170966bb5574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 20 | total loss : Tensor(\"add_3139:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 40 | total loss : Tensor(\"add_3159:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 60 | total loss : Tensor(\"add_3179:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 80 | total loss : Tensor(\"add_3199:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 100 | total loss : Tensor(\"add_3219:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:56: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c745b8dbff044e5aa592091c680101f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 120 | total loss : Tensor(\"add_3238:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 140 | total loss : Tensor(\"add_3258:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 160 | total loss : Tensor(\"add_3278:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 180 | total loss : Tensor(\"add_3298:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 200 | total loss : Tensor(\"add_3318:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c55f5c154849d584dd90ca3997fd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 220 | total loss : Tensor(\"add_3337:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 240 | total loss : Tensor(\"add_3357:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 260 | total loss : Tensor(\"add_3377:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 280 | total loss : Tensor(\"add_3397:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 300 | total loss : Tensor(\"add_3417:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d40f56114844569839f2ecc168d367d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 320 | total loss : Tensor(\"add_3436:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 340 | total loss : Tensor(\"add_3456:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 360 | total loss : Tensor(\"add_3476:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 380 | total loss : Tensor(\"add_3496:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 400 | total loss : Tensor(\"add_3516:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8992a85452da4e6893b360040bfe42a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 440 | total loss : Tensor(\"add_3555:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 460 | total loss : Tensor(\"add_3575:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 480 | total loss : Tensor(\"add_3595:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 500 | total loss : Tensor(\"add_3615:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 520 | total loss : Tensor(\"add_3635:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90c8e7c2fbf473692ec2668fd5a8bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 540 | total loss : Tensor(\"add_3654:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 560 | total loss : Tensor(\"add_3674:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 580 | total loss : Tensor(\"add_3694:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 600 | total loss : Tensor(\"add_3714:0\", shape=(), dtype=float32)\n",
      "epochs 1 | Steps 620 | total loss : Tensor(\"add_3734:0\", shape=(), dtype=float32)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:28: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c0bcb41484465abfb4ac9a1260ef09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='MUSIC', max=6.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21df79beea54524ada5fe7a0feea5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 20 | total loss : Tensor(\"add_3763:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 40 | total loss : Tensor(\"add_3783:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 60 | total loss : Tensor(\"add_3803:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 80 | total loss : Tensor(\"add_3823:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 100 | total loss : Tensor(\"add_3843:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023958d982614b7793febb3e19de28e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 120 | total loss : Tensor(\"add_3862:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 140 | total loss : Tensor(\"add_3882:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 160 | total loss : Tensor(\"add_3902:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 180 | total loss : Tensor(\"add_3922:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 200 | total loss : Tensor(\"add_3942:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd0426a3c974d508eb1d1ef0177a458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 220 | total loss : Tensor(\"add_3961:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 240 | total loss : Tensor(\"add_3981:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 260 | total loss : Tensor(\"add_4001:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 280 | total loss : Tensor(\"add_4021:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 300 | total loss : Tensor(\"add_4041:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c83c9715df848c99438f3713871b594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 320 | total loss : Tensor(\"add_4060:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 340 | total loss : Tensor(\"add_4080:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 360 | total loss : Tensor(\"add_4100:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 380 | total loss : Tensor(\"add_4120:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 400 | total loss : Tensor(\"add_4140:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec02c66f42324cce84327b42f4e407c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 440 | total loss : Tensor(\"add_4179:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 460 | total loss : Tensor(\"add_4199:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 480 | total loss : Tensor(\"add_4219:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 500 | total loss : Tensor(\"add_4239:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 520 | total loss : Tensor(\"add_4259:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67514176f94d48a8bf1f41966648c5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 540 | total loss : Tensor(\"add_4278:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 560 | total loss : Tensor(\"add_4298:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 580 | total loss : Tensor(\"add_4318:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 600 | total loss : Tensor(\"add_4338:0\", shape=(), dtype=float32)\n",
      "epochs 2 | Steps 620 | total loss : Tensor(\"add_4358:0\", shape=(), dtype=float32)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587a73dd760f4367a1075cc1e59da342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='MUSIC', max=6.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2569cc550e74eb484d63fc67b080191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 20 | total loss : Tensor(\"add_4387:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 40 | total loss : Tensor(\"add_4407:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 60 | total loss : Tensor(\"add_4427:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 80 | total loss : Tensor(\"add_4447:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 100 | total loss : Tensor(\"add_4467:0\", shape=(), dtype=float32)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cce97c9c85a4ed995e53d77a2872f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 120 | total loss : Tensor(\"add_4486:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 140 | total loss : Tensor(\"add_4506:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 160 | total loss : Tensor(\"add_4526:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 180 | total loss : Tensor(\"add_4546:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 200 | total loss : Tensor(\"add_4566:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14639e9da0e40d9a1a79db94a224775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 220 | total loss : Tensor(\"add_4585:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 240 | total loss : Tensor(\"add_4605:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 260 | total loss : Tensor(\"add_4625:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 280 | total loss : Tensor(\"add_4645:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 300 | total loss : Tensor(\"add_4665:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ceeeddf97a4b2b836acca953dc245c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 320 | total loss : Tensor(\"add_4684:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 340 | total loss : Tensor(\"add_4704:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 360 | total loss : Tensor(\"add_4724:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 380 | total loss : Tensor(\"add_4744:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 400 | total loss : Tensor(\"add_4764:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a4926ea9bb42dcbc93a4cf330cd759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 440 | total loss : Tensor(\"add_4803:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 460 | total loss : Tensor(\"add_4823:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 480 | total loss : Tensor(\"add_4843:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 500 | total loss : Tensor(\"add_4863:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 520 | total loss : Tensor(\"add_4883:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c95166cb9914a04b964472edf9066da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 3 | Steps 540 | total loss : Tensor(\"add_4902:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 560 | total loss : Tensor(\"add_4922:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 580 | total loss : Tensor(\"add_4942:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 600 | total loss : Tensor(\"add_4962:0\", shape=(), dtype=float32)\n",
      "epochs 3 | Steps 620 | total loss : Tensor(\"add_4982:0\", shape=(), dtype=float32)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efa5b3f26674748af9b99b719afb375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='MUSIC', max=6.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e299b9464a4f5cba7959ead994ed99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 20 | total loss : Tensor(\"add_5011:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 40 | total loss : Tensor(\"add_5031:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 60 | total loss : Tensor(\"add_5051:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 80 | total loss : Tensor(\"add_5071:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 100 | total loss : Tensor(\"add_5091:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366d29ed6f19481689ad6424393fa7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 120 | total loss : Tensor(\"add_5110:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 140 | total loss : Tensor(\"add_5130:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 160 | total loss : Tensor(\"add_5150:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 180 | total loss : Tensor(\"add_5170:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 200 | total loss : Tensor(\"add_5190:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d2eea56c4c43b090cd60448e09720a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 220 | total loss : Tensor(\"add_5209:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 240 | total loss : Tensor(\"add_5229:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 260 | total loss : Tensor(\"add_5249:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 280 | total loss : Tensor(\"add_5269:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 300 | total loss : Tensor(\"add_5289:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8507920459b4d4e8717cdca9c0ccea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 320 | total loss : Tensor(\"add_5308:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 340 | total loss : Tensor(\"add_5328:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 360 | total loss : Tensor(\"add_5348:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 380 | total loss : Tensor(\"add_5368:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 400 | total loss : Tensor(\"add_5388:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3687cd417d485e923450f0bb098394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 440 | total loss : Tensor(\"add_5427:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 460 | total loss : Tensor(\"add_5447:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 480 | total loss : Tensor(\"add_5467:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 500 | total loss : Tensor(\"add_5487:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 520 | total loss : Tensor(\"add_5507:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8b4af450404a21bb0ecb3d2782f953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 4 | Steps 540 | total loss : Tensor(\"add_5526:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 560 | total loss : Tensor(\"add_5546:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 580 | total loss : Tensor(\"add_5566:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 600 | total loss : Tensor(\"add_5586:0\", shape=(), dtype=float32)\n",
      "epochs 4 | Steps 620 | total loss : Tensor(\"add_5606:0\", shape=(), dtype=float32)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c872529b5d1f46658d755020db27aec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='MUSIC', max=6.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78603e3ac5d7486da84ec3622805051c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 5 | Steps 20 | total loss : Tensor(\"add_5635:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 40 | total loss : Tensor(\"add_5655:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 60 | total loss : Tensor(\"add_5675:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 80 | total loss : Tensor(\"add_5695:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 100 | total loss : Tensor(\"add_5715:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3cbbb8d5694234aec4141bfdf7453a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 5 | Steps 120 | total loss : Tensor(\"add_5734:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 140 | total loss : Tensor(\"add_5754:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 160 | total loss : Tensor(\"add_5774:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 180 | total loss : Tensor(\"add_5794:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 200 | total loss : Tensor(\"add_5814:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b1972e4907455da2bfa2762d9a8b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 5 | Steps 220 | total loss : Tensor(\"add_5833:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 240 | total loss : Tensor(\"add_5853:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 260 | total loss : Tensor(\"add_5873:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 280 | total loss : Tensor(\"add_5893:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 300 | total loss : Tensor(\"add_5913:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79ef0261f404e049e57b5b1d74cf899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 5 | Steps 320 | total loss : Tensor(\"add_5932:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 340 | total loss : Tensor(\"add_5952:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 360 | total loss : Tensor(\"add_5972:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 380 | total loss : Tensor(\"add_5992:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 400 | total loss : Tensor(\"add_6012:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a90ca9f7db34241ad6be598dc4ee6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 5 | Steps 440 | total loss : Tensor(\"add_6051:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 460 | total loss : Tensor(\"add_6071:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 480 | total loss : Tensor(\"add_6091:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 500 | total loss : Tensor(\"add_6111:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 520 | total loss : Tensor(\"add_6131:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573cb18484df46dc981bc1214f324c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 5 | Steps 540 | total loss : Tensor(\"add_6150:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 560 | total loss : Tensor(\"add_6170:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 580 | total loss : Tensor(\"add_6190:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 600 | total loss : Tensor(\"add_6210:0\", shape=(), dtype=float32)\n",
      "epochs 5 | Steps 620 | total loss : Tensor(\"add_6230:0\", shape=(), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_class = TrainModel(EPOCHS, unique_train, unique_target, BATCH_NNET_SIZE, BATCH_SONG, optimizer, checkpoint, loss_fn, checkpoint_prefix, \n",
    "                        TOTAL_SONGS, model)\n",
    "train_class.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('haydn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
