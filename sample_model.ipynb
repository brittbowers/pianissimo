{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Net with a Sample (Couple Midi Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy # used for integer targets\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from random import shuffle, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "target = []\n",
    "with open('data/sample_input.json', 'r') as handle:\n",
    "    for line in handle:\n",
    "        song = json.loads(line)\n",
    "        train.append(song['train'])\n",
    "        target.append(song['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = train\n",
    "sample_target = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['time_notes', 'composer', 'title', 'split', 'year', 'duration', 'train', 'target'])\n"
     ]
    }
   ],
   "source": [
    "print(sample_input[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Johann Sebastian Bach'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input[0]['composer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_notes = len(set(sample_input[0]['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2167"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [y for x in sample_train for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = [y for x in test for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = max(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43629"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_notes = len(set(notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43628"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b1c6e6645cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_input' is not defined"
     ]
    }
   ],
   "source": [
    "len(sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqSelfAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    ATTENTION_TYPE_ADD = 'additive'\n",
    "    ATTENTION_TYPE_MUL = 'multiplicative'\n",
    "\n",
    "    def __init__(self,\n",
    "                 units=32,\n",
    "                 attention_width=None,\n",
    "                 attention_type=ATTENTION_TYPE_ADD,\n",
    "                 return_attention=False,\n",
    "                 history_only=False,\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 use_additive_bias=True,\n",
    "                 use_attention_bias=True,\n",
    "                 attention_activation=None,\n",
    "                 attention_regularizer_weight=0.0,\n",
    "                 **kwargs):\n",
    "        \"\"\"Layer initialization.\n",
    "        For additive attention, see: https://arxiv.org/pdf/1806.01264.pdf\n",
    "        :param units: The dimension of the vectors that used to calculate the attention weights.\n",
    "        :param attention_width: The width of local attention.\n",
    "        :param attention_type: 'additive' or 'multiplicative'.\n",
    "        :param return_attention: Whether to return the attention weights for visualization.\n",
    "        :param history_only: Only use historical pieces of data.\n",
    "        :param kernel_initializer: The initializer for weight matrices.\n",
    "        :param bias_initializer: The initializer for biases.\n",
    "        :param kernel_regularizer: The regularization for weight matrices.\n",
    "        :param bias_regularizer: The regularization for biases.\n",
    "        :param kernel_constraint: The constraint for weight matrices.\n",
    "        :param bias_constraint: The constraint for biases.\n",
    "        :param use_additive_bias: Whether to use bias while calculating the relevance of inputs features\n",
    "                                  in additive mode.\n",
    "        :param use_attention_bias: Whether to use bias while calculating the weights of attention.\n",
    "        :param attention_activation: The activation used for calculating the weights of attention.\n",
    "        :param attention_regularizer_weight: The weights of attention regularizer.\n",
    "        :param kwargs: Parameters for parent class.\n",
    "        \"\"\"\n",
    "        self.supports_masking = True\n",
    "        self.units = units\n",
    "        self.attention_width = attention_width\n",
    "        self.attention_type = attention_type\n",
    "        self.return_attention = return_attention\n",
    "        self.history_only = history_only\n",
    "        if history_only and attention_width is None:\n",
    "            self.attention_width = int(1e9)\n",
    "\n",
    "        self.use_additive_bias = use_additive_bias\n",
    "        self.use_attention_bias = use_attention_bias\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
    "        self.kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
    "        self.attention_activation = tf.keras.activations.get(attention_activation)\n",
    "        self.attention_regularizer_weight = attention_regularizer_weight\n",
    "        self._backend = tf.keras.backend.backend()\n",
    "\n",
    "        if attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self.Wx, self.Wt, self.bh = None, None, None\n",
    "            self.Wa, self.ba = None, None\n",
    "        elif attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self.Wa, self.ba = None, None\n",
    "        else:\n",
    "            raise NotImplementedError('No implementation for attention type : ' + attention_type)\n",
    "\n",
    "        super(SeqSelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'units': self.units,\n",
    "            'attention_width': self.attention_width,\n",
    "            'attention_type': self.attention_type,\n",
    "            'return_attention': self.return_attention,\n",
    "            'history_only': self.history_only,\n",
    "            'use_additive_bias': self.use_additive_bias,\n",
    "            'use_attention_bias': self.use_attention_bias,\n",
    "            'kernel_initializer': tf.keras.regularizers.serialize(self.kernel_initializer),\n",
    "            'bias_initializer': tf.keras.regularizers.serialize(self.bias_initializer),\n",
    "            'kernel_regularizer': tf.keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            'bias_regularizer': tf.keras.regularizers.serialize(self.bias_regularizer),\n",
    "            'kernel_constraint': tf.keras.constraints.serialize(self.kernel_constraint),\n",
    "            'bias_constraint': tf.keras.constraints.serialize(self.bias_constraint),\n",
    "            'attention_activation': tf.keras.activations.serialize(self.attention_activation),\n",
    "            'attention_regularizer_weight': self.attention_regularizer_weight,\n",
    "        }\n",
    "        base_config = super(SeqSelfAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            self._build_additive_attention(input_shape)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            self._build_multiplicative_attention(input_shape)\n",
    "        super(SeqSelfAttention, self).build(input_shape)\n",
    "\n",
    "    def _build_additive_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wt = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wt'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        self.Wx = self.add_weight(shape=(feature_dim, self.units),\n",
    "                                  name='{}_Add_Wx'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_additive_bias:\n",
    "            self.bh = self.add_weight(shape=(self.units,),\n",
    "                                      name='{}_Add_bh'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(self.units, 1),\n",
    "                                  name='{}_Add_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Add_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def _build_multiplicative_attention(self, input_shape):\n",
    "        feature_dim = input_shape[2]\n",
    "\n",
    "        self.Wa = self.add_weight(shape=(feature_dim, feature_dim),\n",
    "                                  name='{}_Mul_Wa'.format(self.name),\n",
    "                                  initializer=self.kernel_initializer,\n",
    "                                  regularizer=self.kernel_regularizer,\n",
    "                                  constraint=self.kernel_constraint)\n",
    "        if self.use_attention_bias:\n",
    "            self.ba = self.add_weight(shape=(1,),\n",
    "                                      name='{}_Mul_ba'.format(self.name),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      regularizer=self.bias_regularizer,\n",
    "                                      constraint=self.bias_constraint)\n",
    "\n",
    "    def call(self, inputs, mask=None, **kwargs):\n",
    "        if isinstance(inputs, list):\n",
    "            inputs, positions = inputs\n",
    "            positions = K.cast(positions, 'int32')\n",
    "            mask = mask[1]\n",
    "        else:\n",
    "            positions = None\n",
    "\n",
    "        input_len = K.shape(inputs)[1]\n",
    "\n",
    "        if self.attention_type == SeqSelfAttention.ATTENTION_TYPE_ADD:\n",
    "            e = self._call_additive_emission(inputs)\n",
    "        elif self.attention_type == SeqSelfAttention.ATTENTION_TYPE_MUL:\n",
    "            e = self._call_multiplicative_emission(inputs)\n",
    "\n",
    "        if self.attention_activation is not None:\n",
    "            e = self.attention_activation(e)\n",
    "        e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
    "        if self.attention_width is not None:\n",
    "            ones = tf.ones((input_len, input_len))\n",
    "            if self.history_only:\n",
    "                local = tf.linalg.band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width - 1),\n",
    "                    0,\n",
    "                )\n",
    "            else:\n",
    "                local = tf.linalg.band_part(\n",
    "                    ones,\n",
    "                    K.minimum(input_len, self.attention_width // 2),\n",
    "                    K.minimum(input_len, (self.attention_width - 1) // 2),\n",
    "                )\n",
    "            e = e * K.expand_dims(local, 0)\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            e = K.permute_dimensions(K.permute_dimensions(e * mask, (0, 2, 1)) * mask, (0, 2, 1))\n",
    "\n",
    "        # a_{t} = \\text{softmax}(e_t)\n",
    "        s = K.sum(e, axis=-1)\n",
    "        s = K.tile(K.expand_dims(s, axis=-1), K.stack([1, 1, input_len]))\n",
    "        a = e / (s + K.epsilon())\n",
    "\n",
    "        # l_t = \\sum_{t'} a_{t, t'} x_{t'}\n",
    "        v = K.batch_dot(a, inputs)\n",
    "        if self.attention_regularizer_weight > 0.0:\n",
    "            self.add_loss(self._attention_regularizer(a))\n",
    "\n",
    "        if positions is not None:\n",
    "            pos_num = K.shape(positions)[1]\n",
    "            batch_indices = K.tile(K.expand_dims(K.arange(K.shape(inputs)[0]), axis=-1), K.stack([1, pos_num]))\n",
    "            pos_indices = K.stack([batch_indices, positions], axis=-1)\n",
    "            v = tf.gather_nd(v, pos_indices)\n",
    "            a = tf.gather_nd(a, pos_indices)\n",
    "\n",
    "        if self.return_attention:\n",
    "            return [v, a]\n",
    "        return v\n",
    "\n",
    "    def _call_additive_emission(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size, input_len = input_shape[0], input_shape[1]\n",
    "\n",
    "        # h_{t, t'} = \\tanh(x_t^T W_t + x_{t'}^T W_x + b_h)\n",
    "        q, k = K.dot(inputs, self.Wt), K.dot(inputs, self.Wx)\n",
    "        q = K.tile(K.expand_dims(q, 2), K.stack([1, 1, input_len, 1]))\n",
    "        k = K.tile(K.expand_dims(k, 1), K.stack([1, input_len, 1, 1]))\n",
    "        if self.use_additive_bias:\n",
    "            h = K.tanh(q + k + self.bh)\n",
    "        else:\n",
    "            h = K.tanh(q + k)\n",
    "\n",
    "        # e_{t, t'} = W_a h_{t, t'} + b_a\n",
    "        if self.use_attention_bias:\n",
    "            e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))\n",
    "        else:\n",
    "            e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))\n",
    "        return e\n",
    "\n",
    "    def _call_multiplicative_emission(self, inputs):\n",
    "        # e_{t, t'} = x_t^T W_a x_{t'} + b_a\n",
    "        e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))\n",
    "        if self.use_attention_bias:\n",
    "            e = e + self.ba\n",
    "        return e\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape, pos_shape = input_shape\n",
    "            output_shape = (input_shape[0], pos_shape[1], input_shape[2])\n",
    "        else:\n",
    "            output_shape = input_shape\n",
    "        if self.return_attention:\n",
    "            attention_shape = (input_shape[0], output_shape[1], input_shape[1])\n",
    "            return [output_shape, attention_shape]\n",
    "        return output_shape\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if isinstance(inputs, list):\n",
    "            mask = mask[1]\n",
    "        if self.return_attention:\n",
    "            return [mask, None]\n",
    "        return mask\n",
    "\n",
    "    def _attention_regularizer(self, attention):\n",
    "        batch_size = K.cast(K.shape(attention)[0], K.floatx())\n",
    "        input_len = K.shape(attention)[-1]\n",
    "        return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(\n",
    "            attention,\n",
    "            K.permute_dimensions(attention, (0, 2, 1))) - tf.eye(input_len))) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def get_custom_objects():\n",
    "        return {'SeqSelfAttention': SeqSelfAttention}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(seq_len, unique_notes, dropout=0.3, output_emb=100, rnn_unit=128, dense_unit=64):\n",
    "    inputs = tf.keras.layers.Input(shape=(seq_len,))\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=unique_notes+1, output_dim=output_emb, input_length=seq_len)(inputs)\n",
    "    forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit, return_sequences=True))(embedding)\n",
    "    forward_pass , att_vector = SeqSelfAttention(\n",
    "        return_attention=True,\n",
    "        attention_activation='sigmoid', \n",
    "        attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "        attention_width=50, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "        bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "        attention_regularizer_weight=1e-4,\n",
    "        )(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit, return_sequences=True))(forward_pass)\n",
    "    forward_pass , att_vector2 = SeqSelfAttention(\n",
    "        return_attention=True,\n",
    "        attention_activation='sigmoid', \n",
    "        attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "        attention_width=50, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "        bias_regularizer=tf.keras.regularizers.l1(1e-4),\n",
    "        attention_regularizer_weight=1e-4,\n",
    "        )(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(rnn_unit))(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dropout(dropout)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.Dense(dense_unit)(forward_pass)\n",
    "    forward_pass = tf.keras.layers.LeakyReLU()(forward_pass)\n",
    "    outputs = tf.keras.layers.Dense(unique_notes+1, activation = \"softmax\")(forward_pass)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='generate_scores_rnn')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(50, unique_notes+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generate_scores_rnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 50, 100)           4363000   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 50, 256)           176640    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_4 (SeqSel [(None, 50, 256), (None,  65537     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 50, 256)           296448    \n",
      "_________________________________________________________________\n",
      "seq_self_attention_5 (SeqSel [(None, 50, 256), (None,  65537     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 256)               296448    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 43630)             2835950   \n",
      "=================================================================\n",
      "Total params: 8,116,008\n",
      "Trainable params: 8,116,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,40,5):\n",
    "    batch = random.sample([y for x in sample_target[i:i+5] for y in x], 10000)\n",
    "    print(len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "  \n",
    "    def __init__(self, epochs, sample_train, sample_target, batch_nnet_size, batch_song, optimizer, checkpoint, loss_fn,\n",
    "               checkpoint_prefix, total_songs, model):\n",
    "        self.epochs = epochs\n",
    "        self.sample_train = sample_train\n",
    "        self.sample_target = sample_target\n",
    "        self.batch_nnet_size = batch_nnet_size\n",
    "        self.batch_song = batch_song\n",
    "        self.optimizer = optimizer\n",
    "        self.checkpoint = checkpoint\n",
    "        self.loss_fn = loss_fn\n",
    "        self.checkpoint_prefix = checkpoint_prefix\n",
    "        self.total_songs = total_songs\n",
    "        self.model = model\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in tqdm_notebook(range(self.epochs),desc='epochs'):\n",
    "            # for each epochs, we shuffle the list of all the datasets\n",
    "            c = list(zip(self.sample_train, self.sample_target))\n",
    "            shuffle(c)\n",
    "            self.sample_train, self.sample_target = zip(*c)\n",
    "            loss_total = 0\n",
    "            steps = 0\n",
    "            steps_nnet = 0\n",
    "\n",
    "            # Iterate all songs by the length of sample input (total_songs) and batches (batch_song)\n",
    "            for i in tqdm_notebook(range(0,self.total_songs, self.batch_song), desc='MUSIC'):\n",
    "                # EXAMPLE: [0,5,10,15,20] FOR TOTAL_SONGS = 20 AND BATCH_SONG = 5\n",
    "                steps += 1\n",
    "                #inputs_nnet_large, outputs_nnet_large = generate_batch_song(\n",
    "                 #   self.sample_input, self.batch_song, start_index=i, fs=self.frame_per_second, \n",
    "                  #  seq_len=seq_len, use_tqdm=False) # We use the function that have been defined here\n",
    "                #inputs_nnet_large = np.array(self.note_tokenizer.transform(inputs_nnet_large), dtype=np.int32)\n",
    "                #outputs_nnet_large = np.array(self.note_tokenizer.transform(outputs_nnet_large), dtype=np.int32)\n",
    "                \n",
    "                # EXAMPLE LARGE INPUTS = ARRAY([1,2,3,4],[2,3,4,5],[2,3,4,5],[2,3,4,5],[1,2,3,4])\n",
    "                input_batch = [y for x in self.sample_train[i:i+self.batch_song] for y in x]\n",
    "                output_batch = [y for x in self.sample_target[i:i+self.batch_song] for y in x]\n",
    "                c = list(zip(input_batch, output_batch))\n",
    "                sample = random.sample(c, 10000)\n",
    "                input_batch, output_batch = zip(*sample)\n",
    "                inputs_nnet_large = np.array(input_batch)\n",
    "                outputs_nnet_large = np.array(output_batch)\n",
    "\n",
    "                # Get an index of all windows in a song\n",
    "                index_shuffled = np.arange(start=0, stop=len(inputs_nnet_large))\n",
    "                np.random.shuffle(index_shuffled)\n",
    "                \n",
    "                for nnet_steps in tqdm_notebook(range(0,len(index_shuffled),self.batch_nnet_size)):\n",
    "                    steps_nnet += 1\n",
    "                    current_index = index_shuffled[nnet_steps:nnet_steps+self.batch_nnet_size]\n",
    "\n",
    "                    inputs_nnet, outputs_nnet = inputs_nnet_large[current_index], outputs_nnet_large[current_index]\n",
    "\n",
    "                    # To make sure no exception thrown by tensorflow on autograph\n",
    "                    if len(inputs_nnet) // self.batch_nnet_size != 1:\n",
    "                        break\n",
    "                    loss = self.train_step(inputs_nnet, outputs_nnet)\n",
    "                    loss_total += tf.math.reduce_sum(loss)\n",
    "                    if steps_nnet % 20 == 0:\n",
    "                        print(\"epochs {} | Steps {} | total loss : {}\".format(epoch + 1, steps_nnet,loss_total))\n",
    "\n",
    "                    checkpoint.save(file_prefix = self.checkpoint_prefix)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, inputs, targets):\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = self.model(inputs)\n",
    "            loss = self.loss_fn(targets, prediction)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Nadam()\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 model=model)\n",
    "checkpoint_dir = 'models/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "loss_fn = sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "EPOCHS = 2\n",
    "BATCH_SONG = 5\n",
    "BATCH_NNET_SIZE = 96\n",
    "TOTAL_SONGS = len(sample_input)\n",
    "FRAME_PER_SECOND = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad39a66c7bb45a39c790e0e285ff37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epochs', max=2, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55bd73ffd1349c99687783b2c50d00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MUSIC', max=8, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9867b56eb2246c49dc0d61aa6f5351c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 20 | total loss : 10832.0732421875\n",
      "epochs 1 | Steps 40 | total loss : 21231.33984375\n",
      "epochs 1 | Steps 60 | total loss : 31167.056640625\n",
      "epochs 1 | Steps 80 | total loss : 40718.390625\n",
      "epochs 1 | Steps 100 | total loss : 50313.7109375\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c916d5e70c499db86514cff65b236f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 120 | total loss : 59818.59765625\n",
      "epochs 1 | Steps 140 | total loss : 68656.671875\n",
      "epochs 1 | Steps 160 | total loss : 77546.78125\n",
      "epochs 1 | Steps 180 | total loss : 85468.1484375\n",
      "epochs 1 | Steps 200 | total loss : 93271.1328125\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d862becfb3e423e8ae801d589a8b987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 220 | total loss : 102166.140625\n",
      "epochs 1 | Steps 240 | total loss : 112415.7421875\n",
      "epochs 1 | Steps 260 | total loss : 122380.3046875\n",
      "epochs 1 | Steps 280 | total loss : 132061.421875\n",
      "epochs 1 | Steps 300 | total loss : 141436.53125\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d10ba54bdb47ba85fdebfef4c686b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 320 | total loss : 150375.234375\n",
      "epochs 1 | Steps 340 | total loss : 159406.4375\n",
      "epochs 1 | Steps 360 | total loss : 168318.09375\n",
      "epochs 1 | Steps 380 | total loss : 176797.796875\n",
      "epochs 1 | Steps 400 | total loss : 184858.0\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec953810e4024b4bb5bff63046471643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 440 | total loss : 200343.046875\n",
      "epochs 1 | Steps 460 | total loss : 207611.640625\n",
      "epochs 1 | Steps 480 | total loss : 214769.796875\n",
      "epochs 1 | Steps 500 | total loss : 221442.234375\n",
      "epochs 1 | Steps 520 | total loss : 228157.21875\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d9cd6eac3d472792f91493de6bd9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 540 | total loss : 236321.578125\n",
      "epochs 1 | Steps 560 | total loss : 244680.59375\n",
      "epochs 1 | Steps 580 | total loss : 252365.28125\n",
      "epochs 1 | Steps 600 | total loss : 259966.1875\n",
      "epochs 1 | Steps 620 | total loss : 267199.84375\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2274c9936543e9b059818c53c0869d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 640 | total loss : 274169.1875\n",
      "epochs 1 | Steps 660 | total loss : 281352.78125\n",
      "epochs 1 | Steps 680 | total loss : 287873.5625\n",
      "epochs 1 | Steps 700 | total loss : 294055.25\n",
      "epochs 1 | Steps 720 | total loss : 300448.71875\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f55f0a42c34e599a53d359d3661ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1 | Steps 740 | total loss : 307497.25\n",
      "epochs 1 | Steps 760 | total loss : 317151.4375\n",
      "epochs 1 | Steps 780 | total loss : 326595.4375\n",
      "epochs 1 | Steps 800 | total loss : 335699.625\n",
      "epochs 1 | Steps 820 | total loss : 344257.5\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5075ec2974a7444e8afa8e6190c13cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MUSIC', max=8, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1022bf4a96d24ecb9e18c08593135b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 20 | total loss : 8400.302734375\n",
      "epochs 2 | Steps 40 | total loss : 15711.0361328125\n",
      "epochs 2 | Steps 60 | total loss : 22817.87109375\n",
      "epochs 2 | Steps 80 | total loss : 30245.32421875\n",
      "epochs 2 | Steps 100 | total loss : 37110.68359375\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bc10a23cf44f9cb7c84c8c72166002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 120 | total loss : 44561.30078125\n",
      "epochs 2 | Steps 140 | total loss : 52363.55078125\n",
      "epochs 2 | Steps 160 | total loss : 60124.44140625\n",
      "epochs 2 | Steps 180 | total loss : 68032.71875\n",
      "epochs 2 | Steps 200 | total loss : 75561.9765625\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b44d386402c4fc287fdeac605e3b2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 220 | total loss : 83402.703125\n",
      "epochs 2 | Steps 240 | total loss : 91349.3359375\n",
      "epochs 2 | Steps 260 | total loss : 99019.671875\n",
      "epochs 2 | Steps 280 | total loss : 106521.609375\n",
      "epochs 2 | Steps 300 | total loss : 113792.59375\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c778cb8783744d385bfc9556d9e976d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 320 | total loss : 121258.8359375\n",
      "epochs 2 | Steps 340 | total loss : 130504.90625\n",
      "epochs 2 | Steps 360 | total loss : 139471.203125\n",
      "epochs 2 | Steps 380 | total loss : 148122.828125\n",
      "epochs 2 | Steps 400 | total loss : 156184.609375\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7d3800f1464dc4ab305a3bad4090f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 440 | total loss : 170808.984375\n",
      "epochs 2 | Steps 460 | total loss : 177316.484375\n",
      "epochs 2 | Steps 480 | total loss : 183528.328125\n",
      "epochs 2 | Steps 500 | total loss : 189503.625\n",
      "epochs 2 | Steps 520 | total loss : 195483.90625\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f414bfeab2e42c68759fa185245f87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 540 | total loss : 203575.15625\n",
      "epochs 2 | Steps 560 | total loss : 212322.609375\n",
      "epochs 2 | Steps 580 | total loss : 220441.6875\n",
      "epochs 2 | Steps 600 | total loss : 228297.765625\n",
      "epochs 2 | Steps 620 | total loss : 235884.40625\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658e954e6066467083f1fca4da871685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 640 | total loss : 243720.90625\n",
      "epochs 2 | Steps 660 | total loss : 252363.5625\n",
      "epochs 2 | Steps 680 | total loss : 260527.703125\n",
      "epochs 2 | Steps 700 | total loss : 267933.5\n",
      "epochs 2 | Steps 720 | total loss : 275298.90625\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fad663767c48a4b328ef322e4e0ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 2 | Steps 740 | total loss : 281828.59375\n",
      "epochs 2 | Steps 760 | total loss : 287629.0\n",
      "epochs 2 | Steps 780 | total loss : 293047.5\n",
      "epochs 2 | Steps 800 | total loss : 298328.875\n",
      "epochs 2 | Steps 820 | total loss : 303088.1875\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_class = TrainModel(EPOCHS, sample_train, sample_target, BATCH_NNET_SIZE, BATCH_SONG, optimizer, checkpoint, loss_fn, checkpoint_prefix, \n",
    "                        TOTAL_SONGS, model)\n",
    "train_class.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_s40_ep2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
